name: Weekly Eval Suite

on:
  schedule:
    # Run every Sunday at 00:00 UTC
    - cron: '0 0 * * 0'
  workflow_dispatch:  # Allow manual trigger
    inputs:
      mode:
        description: 'Run mode'
        required: false
        default: 'mock'
        type: choice
        options:
          - mock
          - real
          - dry-run
      category:
        description: 'Eval category (leave empty for all)'
        required: false
        default: ''
        type: string

jobs:
  run-evals:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Determine run mode
        id: mode
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "mode=${{ inputs.mode }}" >> $GITHUB_OUTPUT
            echo "category=${{ inputs.category }}" >> $GITHUB_OUTPUT
          else
            # Scheduled runs use mock mode
            echo "mode=mock" >> $GITHUB_OUTPUT
            echo "category=" >> $GITHUB_OUTPUT
          fi

      - name: Run eval suite
        working-directory: evals
        run: |
          MODE="${{ steps.mode.outputs.mode }}"
          CATEGORY="${{ steps.mode.outputs.category }}"

          ARGS=""
          if [ "$MODE" = "mock" ]; then
            ARGS="--mock"
          elif [ "$MODE" = "dry-run" ]; then
            ARGS="--dry-run"
          fi

          if [ -n "$CATEGORY" ]; then
            ARGS="$ARGS --category $CATEGORY"
          fi

          echo "Running: python runner.py $ARGS"
          python runner.py $ARGS || true  # Don't fail workflow on eval failures

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ github.run_number }}
          path: |
            evals/results/*.json
            evals/SCOREBOARD.md
          retention-days: 90

      - name: Commit updated scoreboard
        if: github.event_name == 'schedule'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add evals/results/*.json evals/SCOREBOARD.md
          git diff --staged --quiet || git commit -m "chore: Update eval scoreboard [skip ci]"
          git push

  notify-on-failure:
    runs-on: ubuntu-latest
    needs: run-evals
    if: failure()
    steps:
      - name: Create issue on failure
        uses: actions/github-script@v7
        with:
          script: |
            const date = new Date().toISOString().split('T')[0];
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Weekly eval run failed - ${date}`,
              body: `The weekly eval suite failed. Check the [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.`,
              labels: ['eval-failure', 'automated']
            });
