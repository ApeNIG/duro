# Daily Log: 2026-02-10

## Session Summary

### Stride Server - Completed
- Finished full buildout (7 phases)
- Added username-based auth for teens (no email required)
- Server running on port 4000, client on 5173

### Duro Named
- Agent OS renamed to "Duro"
- Updated ORCHESTRATOR.md, GUARDRAILS.md, MEMORY.md

### The Fashanus - New Project Created
- Weekly AI-generated family drama series for social media
- Mixed-race British-Nigerian family of 4:
  - Tunde Fashanu (Dad, 35) - Nigerian, marketing, boarding school past
  - Rachel Fashanu (Mum, 37) - British, creative/self-employed
  - Maya Fashanu (Daughter, 11) - Pre-teen, artist, identity struggles
  - Tayo Fashanu (Son, 8) - Loud, helpful, absorbs family tension
- Supporting character: Tiwa (Tunde's step-sister in France)

### Documents Created

```
C:\Users\sibag\.agent\projects\fashanus\
├── PRODUCTION_WORKFLOW.md    # Complete production guide
├── CHARACTER_BIBLE.md        # Full character profiles
├── TOOLS_RESEARCH.md         # Free tools research
├── setup.py                  # Tool installation script
└── arcs\
    └── arc01_the_art_dream.md # First 4-episode arc
```

### Tools Research Completed

**Image Generation (Free):**
- putergenai - Python SDK for Puter.com, access to DALL-E, Flux, Gemini
- Hugging Face Inference API - Free tier

**Text-to-Speech (Free, No API Key):**
- edge-tts - Microsoft Edge TTS, 300+ voices, best option
- ttsfm - OpenAI-compatible TTS

**Video Generation:**
- Manual for now (LTX Studio, Kling AI free tiers)
- APIs exist but mostly paid

### Key Decisions
- Using edge-tts for voice (free, high quality)
- Using putergenai for image generation (requires free account)
- Manual video generation initially
- TikTok as primary platform

## Next Steps
1. Install tools: `python setup.py install`
2. Test voices: `python setup.py test-tts`
3. Create Puter account for image generation
4. Generate character reference images
5. Produce pilot episode

## Files Modified
- C:\Users\sibag\.agent\ORCHESTRATOR.md (renamed to Duro)
- C:\Users\sibag\.agent\GUARDRAILS.md (renamed to Duro)
- C:\Users\sibag\.agent\memory\MEMORY.md (recorded Duro name)
- C:\Users\sibag\.agent\projects\registry.md (added The Fashanus)

---

*Logged by Duro*

### [19:09] Duro MCP Server Build
## Duro MCP Server - Built and Deployed

### What Was Built
Created a full MCP server for Duro at `C:\Users\sibag\duro-mcp\`:
- `config.json` - Configuration and paths
- `memory.py` - Memory load/save operations
- `skills.py` - Skill discovery and execution
- `rules.py` - Rule matching and application
- `duro_mcp_server.py` - Main MCP server with 14 tools

### Tools Exposed
- Memory: `duro_load_context`, `duro_save_memory`, `duro_save_learning`, `duro_log_task`, `duro_log_failure`
- Skills: `duro_list_skills`, `duro_find_skills`, `duro_run_skill`, `duro_get_skill_code`
- Rules: `duro_check_rules`, `duro_list_rules`
- Projects: `duro_get_project`, `duro_list_projects`
- System: `duro_status`

### Issues Fixed
1. Initial server returned `CallToolResult` instead of `list[TextContent]` - fixed to match SuperAGI pattern
2. MCP was added to wrong config file (`settings.json` vs `.claude.json`) - added to global `mcpServers` in `.claude.json`

### Key Learning
Claude Code uses `.claude.json` for global MCP config, NOT `.claude/settings.json`. The `mcpServers` key at the root level is where global servers go.

### Status
Duro MCP is now fully operational and connected. The system can:
- Load full context (soul, memory, rules) at session start
- Persist learnings and memories
- Execute skills
- Check rules against tasks
- Compound intelligence across sessions

### [19:09] Learnings
**Learning (Technical):** Claude Code MCP servers must be added to the global `mcpServers` object in `~/.claude.json`, NOT in `~/.claude/settings.json`. The CLI command `claude mcp add` adds to the correct location.

### [19:09] Task Completed
**Task:** Build Duro MCP Server
**Outcome:** Successfully built and deployed. Server exposes 14 tools for memory, skills, rules, and projects. Connected to Claude Code globally.

### [19:21] Market Research
## Notion Template Market Research (Feb 2026)

### Key Insights from Web Research

**What's Selling in 2026:**
- "Personal command centers" - not just to-do lists
- Templates blending AI, automation, and clean design
- Second brain / life OS systems
- Student semester dashboards
- Freelancer/creator productivity hubs
- Habit tracking + goal systems combined

**What Makes Templates Successful:**
1. **Adaptability** - Users can hide/add modules, not locked into one workflow
2. **Automation** - Pre-built formulas, recurring tasks, monthly rollups
3. **Visual clarity** - Good hierarchy, whitespace, works on mobile
4. **Community/docs** - Discord, Reddit support, or good documentation

**User Pain Points to Solve:**
- "Blank page paralysis" - templates save setup time
- Over-complex systems that get abandoned after 3 days
- Beautiful templates that are a pain to actually use daily
- Templates that don't work on mobile

**Target Audience:**
- People in 20s-30s juggling jobs, school, side projects
- Remote workers needing "personal OS"
- Students, recent grads, freelancers
- "Tinkerers, not minimalism monks"

**Opportunity Areas:**
- Simple templates that actually stick (anti-complexity)
- Templates for specific niches (creators, freelancers)
- Mobile-first designs
- Templates with good onboarding/documentation

### Sources
- plandio.com/blogs/news/best-notion-templates-in-2026
- Gumroad search: "Notion templates 2026 productivity"

### [19:21] Learnings
**Learning (Product Research):** Successful Notion templates in 2026 prioritize: adaptability (users can customize), automation (pre-built formulas), visual clarity (works on mobile), and community support. Anti-complexity sells - templates that actually stick beat beautiful ones that get abandoned.

### [19:59] System Build
Built enhanced dual-store memory system for Duro:
- Created schemas.py with artifact envelope pattern and validation
- Created index.py with SQLite query layer (artifacts table with indexes)
- Created artifacts.py with ArtifactStore class
- Added 6 new MCP tools: duro_store_fact, duro_store_decision, duro_query_memory, duro_get_artifact, duro_list_artifacts, duro_reindex
- Architecture: JSON files canonical, SQLite for queries, schema validation at write-time
- Artifact types: fact, decision, skill, rule, log
- Directory structure: memory/facts/, memory/decisions/, memory/logs/, etc.

### [20:01] Task Completed
**Task:** Build dual-store memory system for Duro with artifact envelope pattern
**Outcome:** Successfully created: schemas.py (validation), index.py (SQLite layer), artifacts.py (ArtifactStore class). Added 6 new MCP tools (duro_store_fact, duro_store_decision, duro_query_memory, duro_get_artifact, duro_list_artifacts, duro_reindex). Architecture: JSON files canonical, SQLite as query index, schema validation at write-time. Ready for use after MCP server restart.

### [20:01] Learnings
**Learning (Technical):** Dual-store pattern for AI memory: Use JSON files as canonical source (human-readable, git-friendly, portable) and SQLite as query index (fast filtering, aggregation). Validate schema at write-time, compute hash for integrity. Artifact envelope wraps all types with consistent metadata (id, type, version, created_at, sensitivity, tags, source, data).

### [20:19] Testing Session
Tested all Duro MCP tools - artifacts, skills, rules, and memory systems all operational.

### [20:19] Learnings
**Learning (Technical):** Duro MCP server exposes 20+ tools across 5 categories: memory, artifacts, skills, rules, and projects. All tools follow consistent patterns with structured JSON responses.

### [20:19] Task Completed
**Task:** Test Duro artifact tools
**Outcome:** Successfully tested duro_store_fact, duro_store_decision, duro_list_artifacts, duro_query_memory, duro_get_artifact. Created 2 test artifacts.

### [20:19] Failure Logged
**Task:** Run generate_tts skill via duro_run_skill
**Error:** Skill execution timed out after 5 minutes
**Lesson:** Check that skill dependencies (edge-tts) are installed and network is available before running TTS skills. Consider adding timeout parameter to skill runner.

### [20:30] Task Completed
**Task:** Implement three reliability layer improvements for Duro
**Outcome:** Completed all three: (A) verify_and_store_fact skill with truth hygiene workflow, (B) fact_verification hard rule requiring sources for high-confidence facts, (C) skill metadata extended with operational fields (requires_network, timeout_seconds, dependencies, side_effects, fallback_workflow, pre_checks). Updated schemas.py, artifacts.py, duro_mcp_server.py, rules/index.json, skills/index.json.

### [20:30] Learnings
**Learning (Architecture):** Reliability layer for agent memory requires: (1) schema validation at write-time with auto-downgrade for violations, (2) operational metadata on skills for pre-execution checks, (3) structured enforcement rules that output allow/deny/constraints decisions, (4) compound skills that chain verification before storage.

### [21:12] Task Completed
**Task:** Test duro_delete_artifact function
**Outcome:** All tests passed: normal delete, verify removal, nonexistent artifact handling, sensitive artifact protection, force delete. Audit logs confirmed working - stored in memory/logs/deletions.jsonl as append-only JSONL (intentionally outside artifact system to prevent circular deletion).

### [21:12] Learnings
**Learning (Architecture):** Deletion audit logs are stored as raw JSONL in memory/logs/deletions.jsonl, NOT as artifacts. This is intentional - audit logs shouldn't be deletable artifacts themselves (would create circular dependency). Logs capture: timestamp, artifact_id, type, sensitivity, file_hash, reason, force_used. Written BEFORE deletion so record exists even if delete fails.

### [21:19] Task Completed
**Task:** Implement audit log improvements: integrity chain + query tool
**Outcome:** Added two improvements: (1) Integrity chain - each deletion entry now includes prev_hash (hash of previous line, or "genesis" for first) and entry_hash for tamper-evidence. (2) New duro_query_audit_log tool - queries deletions.jsonl with filters (event_type, artifact_id, search_text, since, limit) and optional verify_chain to validate integrity chain. Requires MCP restart to activate.

### [21:19] Learnings
**Learning (Architecture):** Append-only JSONL audit logs can be made tamper-evident with a simple integrity chain: each entry stores prev_hash (hash of previous line) and entry_hash (hash of current entry). First entry uses "genesis" as prev_hash. Chain verification reads sequentially and compares expected vs actual prev_hash. Broken chain indicates tampering or corruption.

### [21:57] Audit Chain Repair
## Audit Chain Migration Completed

Fixed broken integrity chain in `deletions.jsonl` audit log.

### Issues Fixed
- Entries 1-5 had broken prev_hash linkage (hash mismatch, truncated 16-char hashes)
- Missing chain_version field on legacy entries
- Repair script crashed with Unicode error on Windows (exit code 1)
- No meta-audit trail for repair operations

### Solution
1. Created `repair_audit_chain.py` v1.0.0 migration script with:
   - UTF-8 output forcing for Windows compatibility
   - mtime/size checks to detect concurrent modifications
   - Atomic write via temp file
   - Canonical JSON matching runtime exactly
   - Proper exit codes (0 success, 1 failure)

2. Repaired all 6 entries with:
   - Full 64-char SHA-256 hashes
   - Proper prev_hash → entry_hash linkage
   - chain_version: 1 on all entries

3. Created governance artifacts:
   - `deletions.jsonl.backup` - original broken chain preserved
   - `audit_repairs.jsonl` - meta-audit record with backup/repaired hashes

### Files
- `.agent/memory/logs/deletions.jsonl` - repaired (6 entries, chain valid)
- `.agent/memory/logs/deletions.jsonl.backup` - original backup
- `.agent/memory/logs/audit_repairs.jsonl` - migration record
- `duro-mcp/repair_audit_chain.py` - frozen migration script v1.0.0

### Verification
Chain now validates: Entry 1 (null) → Entry 2 → Entry 3 → Entry 4 → Entry 5 → Entry 6

### [21:57] Task Completed
**Task:** Repair broken audit chain integrity in Duro MCP server
**Outcome:** Successfully migrated 6 entries to chain_version 1 with proper SHA-256 hashing and prev_hash linkage. Created backup, meta-audit record, and frozen migration script. Chain now validates completely.

### [21:57] Learnings
**Learning (Governance):** Audit log repairs must be auditable themselves - always create a meta-audit record (audit_repairs.jsonl) with backup hash, repaired hash, timestamp, and script version. This prevents "we rewrote history" ambiguity.

### [21:57] Learnings
**Learning (Technical):** Windows terminals using CP1252 encoding crash on emoji characters. Use sys.stdout.reconfigure(encoding='utf-8', errors='replace') at script start, or avoid emojis entirely in CLI output.

### [22:16] Task Completed
**Task:** Implement Duro Orchestration Phase 1
**Outcome:** Created orchestrator.py with: normalize_intent(), apply_rules(), select_plan(), execute_plan(), write_run_log(). Added MCP tools: duro_orchestrate, duro_list_runs, duro_get_run. Routing table for store_fact, store_decision, delete_artifact. Run logs saved to ~/.agent/memory/runs/. Includes dry_run, sensitivity detection, rule-based constraints.

### [22:17] Session Log
## Duro Hardening + Orchestration Phase 1

### Audit System Upgrades
1. **Per-link status table** - `duro_query_audit_log` now shows compact table with entry_no, timestamp, entry_hash_len, prev_hash_len, link_ok columns. Catches truncated-hash regressions instantly.

2. **File locking on deletion writes** - Added cross-platform locking (msvcrt on Windows, fcntl on Unix) around the critical section in delete_artifact. Prevents race conditions where concurrent deletes fork the chain.

3. **Meta-audit repair logging** - New `audit_repairs.jsonl` log and tools `duro_log_audit_repair` + `duro_query_repair_log`. Earlier chain migration already logged.

### Orchestration Phase 1 Implemented
New file: `orchestrator.py`

Core functions:
- `normalize_intent()` - Canonicalizes intent strings
- `apply_rules()` - Checks rules, makes ALLOW/CONSTRAIN/DENY decisions
- `select_plan()` - Deterministic routing table
- `execute_plan()` - Runs skill or tool
- `write_run_log()` - Writes canonical JSON to runs/

New MCP tools:
- `duro_orchestrate` - Main entry point
- `duro_list_runs` - Query run history
- `duro_get_run` - Get full run details

Routing table:
- store_fact + high confidence + no sources → verify_and_store_fact
- store_fact + else → duro_store_fact
- store_decision → duro_store_decision
- delete_artifact → duro_delete_artifact

Guardrails:
- Sensitivity auto-detection (PII patterns → internal/sensitive)
- Rule DENY stops execution
- Rule CONSTRAIN modifies routing
- Server version + schema version in every run log

Run logs stored at: ~/.agent/memory/runs/run_*.json

### [22:18] Learnings
**Learning (Architecture):** Orchestration pattern: thin routing layer (intent → rules → skill → log) is better than fat orchestrator with embedded logic. One new concept (a "run") ties everything together. Deterministic routing tables beat clever LLM planners for debuggability.

### [22:45] Session Log
## Orchestration Phase 2: Executable Skills

### Problem
`verify_and_store_fact` skill was a declarative workflow spec (WORKFLOW_STEPS) but had no executor. Orchestration test timed out after 5 minutes because there was no `run()` function.

### Solution: Option 3 - Executable Skills with Tools Dict

**Design principle:** Skills describe "what" and "in what order", orchestrator supplies the "how" (which server/tool executes).

### Changes Made

#### 1. skills.py - New Interface
- Added `run_skill_with_tools(skill_name, args, tools, context, timeout)` method
- Dynamically loads skill module and calls `run()` function
- Checks `REQUIRES` list against provided tools before execution
- Threading-based timeout (default 60s)
- Added `get_skill_meta()` for introspection

#### 2. orchestrator.py - Tools Dict Builder
- `_build_tools_dict(run_id)` creates capability wrappers:
  - `tools["search"]` - web search (stub if not configured)
  - `tools["read"]` - read webpage (stub if not configured)
  - `tools["store_fact"]` - wrapped artifact store
  - `tools["store_decision"]` - wrapped artifact store
  - `tools["log"]` - simple logging
- `set_external_tools()` to inject real callables from other MCP servers
- `EXTERNAL_TOOL_MAP` for future provider mapping

#### 3. orchestrator.py - Degraded Fallback
- `_degraded_fallback_store_fact()` when skill fails/timeouts:
  - Caps confidence at 0.5
  - Adds `needs_verification` tag
  - Sets evidence_type="none", provenance="unknown"
  - Outcome = `degraded_success` (not failure)

#### 4. verify_and_store_fact.py - Rewritten
```python
SKILL_META = {"name": "verify_and_store_fact", "tier": "core", ...}
REQUIRES = ["search", "read", "store_fact"]

def run(args, tools, context) -> dict:
    # 1. Search for sources
    # 2. Read top pages, extract snippets
    # 3. Calculate confidence from evidence quality
    # 4. Store via tools["store_fact"]
    # Returns {success, artifact_id, sources_found, confidence, ...}
```

Pure function - no networking logic, no server names. Uses tools dict exclusively.

### Architecture Pattern
- Skills are portable (don't know about superagi, duro internals)
- Orchestrator is the integration point
- Degraded fallback ensures orchestration never hard-fails on verification
- Worst case: stores clearly marked "needs verification" fact

### Server Version
- SERVER_BUILD: 1.0.0 → 1.1.0
- SCHEMA_VERSION: 1.0 → 1.1

### Test Status
Requires restart. Expected behavior:
- High confidence + no sources → routes to verify_and_store_fact
- Skill loads, REQUIRES checked
- Search stub returns error → skill fails
- Degraded fallback → stores as unverified
- Outcome: degraded_success

### [22:45] Learnings
**Learning (Architecture):** Skill portability rule: skills should never import or know about specific MCP servers. The orchestrator builds a tools dict with capability wrappers. Skills just call tools['search'], tools['store_fact'], etc. This makes skills portable across different tool providers.

### [22:45] Learnings
**Learning (Architecture):** Degraded fallback > hard failure for compound skills. When verification fails, store as unverified (confidence=0.5, tag=needs_verification) rather than refusing entirely. The system stays useful while clearly marking uncertainty.

### [22:52] Session Log
Tested Duro orchestration loop:
- Ran dry run and live orchestration for store_fact intent
- Listed and inspected runs (found earlier failed run due to 5min timeout)
- Reviewed verify_and_store_fact skill code - network calls caused timeout
- Listed all skills (4 total: 2 core, 2 tested)
- Listed all rules (5 total: 3 hard, 2 soft)
- Checked rules for high-confidence fact storage - triggers verification requirement
- Stored low-confidence fact successfully (bypasses verification)
- Queried memory (4 artifacts: 2 facts, 2 decisions)
- Checked system status - all operational

Orchestration loop working correctly: routes intents → checks rules → selects tool/skill → executes → logs runs.

### [22:52] Task Completed
**Task:** Test Duro orchestration loop
**Outcome:** Success - verified intent routing, rule checking, tool/skill selection, execution, and run logging all working correctly

### [23:02] Task Completed
**Task:** Fix verify_and_store_fact timeout issue
**Outcome:** Added 30s timeout handling with graceful degradation. Skill now completes in 41ms instead of timing out at 5 minutes. Pushed to GitHub.

### [23:16] Task Completed
**Task:** Fix property scraper missing Manchester areas
**Outcome:** Found wrong Rightmove region IDs for Moston (17641), Newton Heath (18316), Miles Platting (17252). Fixed and pushed to GitHub.

### [23:34] Task Completed
**Task:** Research synthesis for The Fashanus
**Outcome:** Created comprehensive RESEARCH_SYNTHESIS.md with insights from boarding school syndrome, family systems theory, parentification, mixed-race identity development, and Nigerian diaspora dynamics. Includes specific character improvements and 5 research-driven conflict storylines.

### [23:41] Task Completed
**Task:** Revise The Fashanus character bible with research insights
**Outcome:** Rewrote CHARACTER_BIBLE.md with: show thesis, unspoken family agreement, research-based behavioral patterns for each character, specific triggers/wounds, "The Unsaid" for each character, family triangle dynamics, rooms as emotional spaces, episode design principles.
