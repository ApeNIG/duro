# Memory Log - 2026-02-18

### [01:02] Learnings
**Learning (Process):** When building UI for a product, always create visual mockups FIRST using design tools (like Pencil MCP) before implementing code. This allows for faster iteration on layout/design decisions without the overhead of code changes, better stakeholder alignment before committing development time, and clearer visual direction that can be referenced during implementation.

### [01:02] Task Completed
**Task:** Built complete Next.js 14 Studio Web UI for Olootu BYOC Template Platform
**Outcome:** Successfully created 64 files (11,635 lines) including: TypeScript types, API client, layout components (Navbar, Sidebar, Footer), Landing page with hero/features/CTA, Templates gallery with mock data fallback, Template detail page with dynamic form generation (VariableInput supporting text/number/select/image/color/boolean), TemplateRunner with execution flow, Providers page with status and setup guides, Settings page for API key management. Build passes successfully. Pushed to GitHub commit c9cd170.

### [01:02] Task Completed
**Task:** Started creating UI mockups for Olootu Studio using Pencil design tools
**Outcome:** In progress - retrieved Swiss Clean style guide and design system guidelines. Ready to create mockup frames for Landing page, Templates gallery, and Template detail screens. Session ended before completing mockups.

### [01:50] Task Completed
**Task:** Set up Duro eval tracking system
**Outcome:** Created eval_metrics skill (ops/eval_metrics.py) that computes decision review rate, unverified rate, reopen rate. Registered in skills index. Created weekly_eval_metrics checklist. Validated 3 Phase 1 Feedback Loop decisions. Current baseline: 60 real decisions, 50 unverified (after validations), 9 validated, 0% reopen rate.

### [01:59] Task Completed
**Task:** Clear decision review backlog
**Outcome:** Validated 44 decisions in bulk (40 validated, 4 superseded). Unverified rate dropped from 88% to 15%. Only 9 decisions remain needing review. Decision feedback loop now closed.

### [02:02] Learnings
**Learning (Process):** Bulk decision validation is high-leverage: clearing 44 decisions in one session dropped unverified rate from 88% to 15%. Batch reviewing by category (architecture, design, skills, roadmap) is more efficient than one-by-one.

### [02:02] Learnings
**Learning (Technical):** Eval tracking should be Phase 0 in any governance roadmap. Build the scoreboard before building the governance - you can't improve what you don't measure.

### [02:02] Learnings
**Learning (Technical):** When building Python skills that access ArtifactStore, use store.store_fact() not store.store_artifact(). The API is method-per-type (store_fact, store_decision, store_episode), not generic.

### [02:02] Learnings
**Learning (Process):** Critical analysis of governance roadmaps: distinguish between incident-driven improvements (needed now) vs speculative improvements (build when pain appears). The right question is "what's the incident list that motivates this?"

### [02:02] Task Completed
**Task:** Session: Duro upgrade planning and eval tracking setup
**Outcome:** 1) Critically analyzed governance roadmap - identified incident-driven vs speculative improvements. 2) Built eval_metrics skill tracking decision review rate, unverified rate, reopen rate. 3) Created weekly_eval_metrics checklist. 4) Cleared decision backlog: 44 decisions reviewed, unverified rate 88%â†’15%. 5) Stored 3 metrics snapshots as facts for trend tracking.
