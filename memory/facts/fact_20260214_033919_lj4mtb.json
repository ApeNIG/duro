{
  "id": "fact_20260214_033919_lj4mtb",
  "type": "fact",
  "version": "1.1",
  "created_at": "2026-02-14T03:39:19.852589Z",
  "updated_at": null,
  "sensitivity": "public",
  "tags": [
    "idea",
    "concept",
    "architecture",
    "cartridge-memory",
    "future",
    "MemGPT",
    "context-optimization"
  ],
  "source": {
    "workflow": "manual",
    "run_id": null,
    "tool_trace_path": null
  },
  "data": {
    "claim": "Cartridge Memory System: Concept for swappable, domain-specific memory modules loaded on demand. Formally known as \"Virtual Context Management\" (MemGPT/UC Berkeley). Research shows 79-90% token reduction, 26% accuracy improvement possible. Key insight: simple tools beat complex architectures (Letta: filesystem 74% vs specialized tools 68.5%). Recommended approach: incremental task-aware loading rather than full VM system. Duro already has building blocks (proactive_recall, query_memory, lean loading).",
    "source_urls": [
      "https://arxiv.org/abs/2310.08560",
      "https://www.letta.com/blog/benchmarking-ai-agent-memory",
      "https://guptadeepak.com/the-ai-memory-wars-why-one-system-crushed-the-competition-and-its-not-openai/",
      "https://blog.jetbrains.com/research/2025/12/efficient-context-management/"
    ],
    "snippet": "MemGPT: Virtual context management drawing inspiration from hierarchical memory systems in traditional OS. Letta finding: agents achieve 74% accuracy using simple filesystem vs 68.5% with specialized memory tools.",
    "confidence": 0.8,
    "verified": true,
    "evidence_type": "paraphrase",
    "provenance": "web"
  }
}