# Summary: 2026-02-17

## Learnings
- AI video production with stock images + TTS = technically works but emotionally flat. For narrative content like The Fashanus, need: (1) consistent character imagery, (2) real voice acting or better voice direction, (3) music/ambient soundscape, (4) motion on stills. The pipeline works; the craft needs more.
- Phase 4.4 production testing validated the full Duro eval pipeline: episode → actions → close → evaluate → apply. Confidence deltas work correctly (+0.01 per reinforcement). System is production-ready for tracking creative workflows.
- edge-tts is free and works well for prototyping voiceovers, but lacks emotional range needed for narrative content. Voice assignment: en-GB-SoniaNeural for British female characters. Rate parameter (-10% to -15%) helps with pacing.
- moviepy 2.x API changes: use `resized(new_size=)` not `resize(newsize=)`, use `with_duration()` not `set_duration()`, use `with_audio()` not `set_audio()`. Effects API changed significantly - skip fades for quick prototypes.
- Keyword-gated retrieval creates blind spots for new domains. Proactive recall failed for 'design' because it wasn't in RETRIEVAL_TRIGGERS. Every new skill domain would have the same problem. Semantic search should be the default path.
- Keyword-based retrieval gating creates blind spots for new skill domains. Semantic search should always run first, with keywords boosting relevance rather than blocking access. This ensures memory works for any domain without manual keyword additions.
- When debugging "vec_score always 0" issues in Duro semantic search: (1) First verify the database has cosine distance configured with migration status check, (2) Test vector_search directly with Python to confirm embeddings work, (3) Check for key name mismatches between hybrid_search output and explain_score input - the actual keys are "vec_score" and "fts_score", not "vector" and "bm25".
- The Duro MCP database is at index.db (not index.sqlite). Path: ~/.agent/memory/index.db. Always check MCP server config (settings.json) for actual paths before debugging.
- When refactoring dict key names (e.g., "vector" to "vec_score"), search entire codebase for all usages - downstream functions like explain_score may reference old keys and silently return defaults instead of actual values.
- When debugging recurring problems, always investigate root cause not just symptoms. Recent changes (like new server setups) are prime suspects. Think about the full system: multiple machines, sync mechanisms, shared repos, CI/CD. When user points to a clue, follow it immediately.

## Tasks Completed
- Phase 4.4 Production Testing - complete session: Completed both synthetic episode test and real production test (The Fashanus Episode 1). Eval pipeline validated. Produced 35-sec video at $0 cost. User feedback: technically works but emotionally flat - need consistent characters, real voice acting, music. Key learning: pipeline works, craft needs more.
- Implemented Option C semantic-first proactive recall architecture: Modified proactive.py to always search semantically regardless of hot path classification. Keywords now boost scores (+0.05 per tag overlap) instead of gating access. Changed search_mode to 'semantic_first', lowered min_confidence to 0.2. This fix applies to ALL skill domains - current and future - without requiring keyword additions for each new domain.
- Debug and fix vec_score showing 0.00 in Duro semantic search: Found key name mismatch in ranking_config.py:explain_score() - was looking for "vector"/"bm25" but hybrid_search creates "vec_score"/"fts_score". Fixed lines 290 and 299. Cosine distance migration was correctly applied, embeddings work fine (0.70+ similarity scores), only the explain text display was wrong.
- Test and commit explain_score key name fix: Verified vec_score/fts_score keys work correctly, committed and pushed fix (97eceea)
- Commit and push pending duro-mcp changes: Committed 5 changes: semantic-first proactive recall, deferred startup, embeddings fallback, design autocapture category, and 2 migrations. All pushed to origin (bdf736a)
- Design Workout: LORE CRM Landing Page (3 rounds): Completed all 3 rounds. R1: B&W clarity (passed). R2: Systems with 8pt grid + accent (40/50). R3: Quiet Luxury with iterations (45/50). Applied 20% trim and conversion optimizations (mockup, metrics, testimonial, transformation narrative).
- Fix Duro MCP config sync conflict: Root cause: DigitalOcean server auto-syncing Linux paths to shared GitHub repo, overwriting Windows config. Fix: Added config.json to .gitignore, created config.default.json template. Each platform now keeps its own config.
- Build Duro instrumentation system for root cause analysis: Added 4 new artifact types (incident_rca, recent_change, design_reference, checklist_template), 5 new MCP tools, created new_service_checklist template. All tests pass, pushed to both duro-mcp and .agent repos.
- Design Workout: LORE CRM Landing Page: Completed 3 rounds (B&W clarity, Systems, Quiet Luxury). Final score 45/50. Applied 20% trim and conversion optimizations. Learnings saved to .claude/learnings/
- Fix Duro MCP config sync conflict (root cause analysis): Root cause: DO server auto-syncing Linux paths to shared GitHub repo. Fix: Added config.json to .gitignore, created config.default.json template. First incident_rca artifact created as proof of concept.
- Build Debug Gate enforcement for Duro incident RCA: Shipped hard gate in store_incident: 3 passes (repro, boundary, causality+48h scan) + actionable prevention check. Override mechanism with waiver trail. Auto-runs 48h scan, infers risk_tags. New helper tools: debug_gate_start, debug_gate_status. Committed 6fc8a97, pushed to origin.
- Duro status check, health check, and maintenance report: System operational: 2000 artifacts, 99.8% embedding coverage, 0 queue pending. Minor issue: 4 FTS rows missing semantic text.
- Reflective analysis: Duro evolution and growth areas: Identified design as biggest growth area (feedback loops exist, taste compounds). Identified decision validation as key gap - 148 decisions stored, unknown if they worked. This is the next growth frontier.
- Critical analysis of Decision Closure System spec: Challenged initial spec. Found existing duro_validate_decision tool. Proposed Option B: enhance existing primitives instead of new artifact type. Key additions: duro_list_unreviewed_decisions (surfacing), append-only validation history, auto-context in review flow. User confirmed this is the right approach.
- Fix 4 FTS rows missing semantic text: Root cause: new artifact types (incident_rca, recent_change, checklist_template, design_reference) not handled in artifact_to_text() and _extract_title(). Fixed by adding handlers to both embeddings.py and index.py. Reindexed 4 affected artifacts. FTS coverage now 100%. Committed 48e02ef.

## Stats
- Original size: 24074 chars
- Total learnings: 41
- Tasks completed: 26
- Failures logged: 0